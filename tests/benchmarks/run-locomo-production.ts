#!/usr/bin/env npx tsx
/**
 * LoCoMo Production Benchmark Runner
 *
 * Runs the LoCoMo retrieval quality benchmark using the FULL PRODUCTION pipeline.
 * This uses wireContext() to get all production services including:
 * - QueryRewriteService (HyDE + expansion)
 * - EntityIndex (entity-aware filtering)
 * - FeedbackQueue (RL scoring)
 * - Full embedding/vector services
 *
 * Usage:
 *   npx tsx tests/benchmarks/run-locomo-production.ts [options]
 *
 * Options:
 *   --sessions N      Number of sessions to run (default: 1)
 *   --dialogues N     Dialogues per session (default: 50, ~15 QA pairs)
 *   --hyde            Enable HyDE during query (default: on)
 *   --no-hyde         Disable HyDE during query
 *   --expand          Enable query expansion during query (default: on)
 *   --no-expand       Disable query expansion during query
 *   --chunk-size N    Dialogues per extraction call (default: 1)
 *   --debug           Show detailed query results
 *   --help, -h        Show this help
 */

// Load .env file FIRST before any other imports
import 'dotenv/config';

// Parse command line args BEFORE imports to set env vars
const args = process.argv.slice(2);
const debugMode = args.includes('--debug');
const showHelp = args.includes('--help') || args.includes('-h');

// Compatibility flags from older runner(s): accept but ignore.
// - --real: this runner always uses production services.
// - -e/--embeddings: embeddings are generated by production embedding hooks.
void args.includes('--real');
void args.includes('-e');
void args.includes('--embeddings');

const hasFlag = (flag: string) => args.includes(flag);

// Parse --sessions N
let maxSessions = 1;
const sessionsIdx = args.findIndex(a => a === '--sessions');
if (sessionsIdx >= 0 && args[sessionsIdx + 1]) {
  maxSessions = parseInt(args[sessionsIdx + 1], 10) || 1;
}

// Parse --dialogues N (limit dialogues per session)
// Default: 50 dialogues gives ~15 QA pairs - good balance of speed and statistical significance
let maxDialogues = 50;
const dialoguesIdx = args.findIndex(a => a === '--dialogues');
if (dialoguesIdx >= 0 && args[dialoguesIdx + 1]) {
  maxDialogues = parseInt(args[dialoguesIdx + 1], 10) || 50;
}

// Parse --chunk-size N (dialogues per extraction call)
// Default: 1 dialogue per extraction for precise entry-to-dialogue mapping (63.9% MRR vs 29.7% at chunk-size=8)
let chunkSize = 1;
const chunkSizeIdx = args.findIndex(a => a === '--chunk-size');
if (chunkSizeIdx >= 0 && args[chunkSizeIdx + 1]) {
  chunkSize = parseInt(args[chunkSizeIdx + 1], 10) || 1;
}

// Parse --overlap N (dialogues to overlap between chunks for context continuity)
// Default: 0 overlap with chunk-size=1 (each dialogue extracted independently)
let chunkOverlap = 0;
const overlapIdx = args.findIndex(a => a === '--overlap');
if (overlapIdx >= 0 && args[overlapIdx + 1]) {
  chunkOverlap = parseInt(args[overlapIdx + 1], 10) || 0;
}

// Parse HyDE/expansion flags (default on)
const hydeEnabled = hasFlag('--no-hyde') ? false : true;
const expansionEnabled = hasFlag('--no-expand') ? false : true;

// Parse --raw flag (bypass LLM extraction, ingest dialogues directly)
const rawIngestionMode = hasFlag('--raw');

if (showHelp) {
  console.log(`
LoCoMo Production Benchmark Runner

Uses the FULL PRODUCTION pipeline with all services:
- QueryRewriteService (HyDE + expansion)
- EntityIndex (entity-aware filtering)
- FeedbackQueue (RL scoring)
- Full embedding/vector services

Usage: npx tsx tests/benchmarks/run-locomo-production.ts [options]

Options:
  --sessions N      Number of sessions to run (default: 1)
  --dialogues N     Dialogues per session (default: 50, ~15 QA pairs)
  --hyde            Enable HyDE during query (default: on)
  --no-hyde         Disable HyDE during query
  --expand          Enable query expansion during query (default: on)
  --no-expand       Disable query expansion during query
  --chunk-size N    Dialogues per extraction call (default: 1)
  --overlap N       Dialogues to overlap between chunks (default: 0)
  --raw             Bypass LLM extraction, ingest raw dialogues directly (for testing retrieval)
  --debug           Show detailed query results
  --help, -h        Show this help

Examples:
  npx tsx tests/benchmarks/run-locomo-production.ts                    # 1 session
  npx tsx tests/benchmarks/run-locomo-production.ts --sessions 3       # 3 sessions
  npx tsx tests/benchmarks/run-locomo-production.ts --dialogues 50     # Limit dialogues
  npx tsx tests/benchmarks/run-locomo-production.ts --no-hyde          # Disable HyDE
  npx tsx tests/benchmarks/run-locomo-production.ts --no-expand        # Disable expansion
`);
  process.exit(0);
}

const LOCOMO_VECTOR_PATH = './data/benchmark/locomo-production-vectors.lance';

// Enable embeddings and rerank in config (use env vars with fallbacks)
process.env.AGENT_MEMORY_RERANK_ENABLED = process.env.AGENT_MEMORY_RERANK_ENABLED ?? 'true';
process.env.AGENT_MEMORY_RERANK_TOP_K = process.env.AGENT_MEMORY_RERANK_TOP_K ?? '20';
process.env.AGENT_MEMORY_RERANK_ALPHA = process.env.AGENT_MEMORY_RERANK_ALPHA ?? '0.7';
// Query rewrite features (controlled by CLI flags, but respect env overrides)
process.env.AGENT_MEMORY_QUERY_REWRITE_ENABLED = String(hydeEnabled || expansionEnabled);
process.env.AGENT_MEMORY_HYDE_ENABLED = String(hydeEnabled);
process.env.AGENT_MEMORY_HYDE_DOCUMENT_COUNT = process.env.AGENT_MEMORY_HYDE_DOCUMENT_COUNT ?? '1';
process.env.AGENT_MEMORY_QUERY_EXPANSION_ENABLED = String(expansionEnabled);
// Isolate vectors per benchmark run to avoid cross-run dimension conflicts.
process.env.AGENT_MEMORY_VECTOR_DB_PATH = LOCOMO_VECTOR_PATH;

// Use dynamic imports so env vars take effect before config is built
const Database = (await import('better-sqlite3')).default;
const { drizzle } = await import('drizzle-orm/better-sqlite3');
const schema = await import('../../src/db/schema.js');
const { generateId } = await import('../../src/db/repositories/base.js');
const { applyMigrations } = await import('../fixtures/migration-loader.js');
const { cleanupDbFiles, ensureDataDirectory } = await import('../fixtures/db-utils.js');
const { config: appConfig } = await import('../../src/config/index.js');
const { createRuntime, extractRuntimeConfig, shutdownRuntime } = await import('../../src/core/runtime.js');
const { createRepositories } = await import('../../src/core/factory/repositories.js');
const { createAdaptersWithConfig } = await import('../../src/core/adapters/index.js');
const { wireContext } = await import('../../src/core/factory/context-wiring.js');
const { registerContext, resetContainer } = await import('../../src/core/container.js');
const { executeQueryPipelineAsync, createDependencies } = await import('../../src/services/query/index.js');
const { extract: observeExtract } = await import('../../src/mcp/handlers/observe/extract.handler.js');
const { getEmbeddingQueueStats, generateEmbeddingAsync } = await import('../../src/db/repositories/embedding-hooks.js');
const { LRUCache } = await import('../../src/utils/lru-cache.js');
const pino = (await import('pino')).default;
const { rm } = await import('node:fs/promises');

// Real LoCoMo imports
const { loadLoCoMoDataset, getDatasetStats } = await import('./locomo-adapter.js');
const { evaluateSession, compileBenchmarkResults, printBenchmarkResults } = await import('./locomo-evaluator.js');
import type { LoCoMoDialogue } from './locomo-types.js';
import type { AppContext } from '../../src/core/context.js';

const LOCOMO_DB_PATH = './data/benchmark/locomo-production.db';

// =============================================================================
// SETUP FUNCTIONS
// =============================================================================

async function setupProductionContext(): Promise<{
  ctx: AppContext;
  projectId: string;
  sqlite: InstanceType<typeof Database>;
  db: ReturnType<typeof drizzle>;
  cleanup: () => Promise<void>;
}> {
  ensureDataDirectory('benchmark');
  cleanupDbFiles(LOCOMO_DB_PATH);
  await rm(LOCOMO_VECTOR_PATH, { recursive: true, force: true });

  const sqlite = new Database(LOCOMO_DB_PATH);
  sqlite.pragma('journal_mode = WAL');
  sqlite.pragma('foreign_keys = ON');
  const db = drizzle(sqlite, { schema });

  applyMigrations(sqlite);

  // Create project
  const projectId = generateId();
  db.insert(schema.projects).values({
    id: projectId,
    name: 'LoCoMo Production Benchmark',
    description: 'Project for LoCoMo production benchmark testing',
    rootPath: '/locomo/benchmark',
  }).run();

  // Use config (already loaded with env vars applied)
  const config = appConfig;

  console.log('Production config:', {
    embeddingProvider: config.embedding.provider,
    extractionProvider: config.extraction.provider,
    rerankEnabled: config.rerank.enabled,
    queryRewriteEnabled: config.queryRewrite.enabled,
    hydeEnabled: config.queryRewrite.hydeEnabled,
  });

  // Create runtime
  const runtimeConfig = extractRuntimeConfig(config);
  const runtime = createRuntime(runtimeConfig);

  // Create repositories
  const repos = createRepositories({ db, sqlite });

  // Create adapters
  const adapters = createAdaptersWithConfig(
    { dbType: 'sqlite', db, sqlite, fileLockRepo: repos.fileLocks },
    config
  );

  // Create logger
  const logger = pino({ level: debugMode ? 'debug' : 'info' });

  // Wire the full production context
  const ctx = await wireContext({
    config,
    runtime,
    db,
    sqlite,
    repos,
    adapters,
    logger,
    dbType: 'sqlite',
  });

  // Some production utilities still depend on the process-wide DI container
  // (e.g., duplicate detection uses getPreparedStatement()).
  registerContext(ctx);

  // Initialize vector service for semantic search
  if (ctx.services.vector) {
    await ctx.services.vector.initialize();
  }

  const cleanup = async () => {
    await shutdownRuntime(runtime);
    await adapters.closeRedis();
    sqlite.close();
    cleanupDbFiles(LOCOMO_DB_PATH);
    await rm(LOCOMO_VECTOR_PATH, { recursive: true, force: true });
    resetContainer();
  };

  return { ctx, projectId, sqlite, db, cleanup };
}

// =============================================================================
// INGESTION FUNCTIONS
// =============================================================================

/**
 * Ingest dialogues using the production extraction service
 */
async function ingestWithProductionExtraction(
  ctx: AppContext,
  dialogues: LoCoMoDialogue[],
  scopeType: 'project' | 'session',
  scopeId: string
): Promise<Map<string, string[]>> {
  const entryIdToDiaIds = new Map<string, string[]>();

  // Chunk dialogues into groups for extraction with overlap for context continuity
  const chunks: LoCoMoDialogue[][] = [];
  const step = Math.max(1, chunkSize - chunkOverlap);
  for (let i = 0; i < dialogues.length; i += step) {
    chunks.push(dialogues.slice(i, i + chunkSize));
  }

  let extractedCount = 0;

  for (const chunk of chunks) {
    // Build conversation context
    const context = chunk.map(d => `${d.speaker}: ${d.text}`).join('\n');

    try {
      // Production ingestion path:
      // - Extract via ExtractionService
      // - Dedup/threshold and store via observe.extract handler helpers
      // - Embeddings are queued asynchronously via repository embedding hooks
      const res = await observeExtract(ctx, {
        context,
        contextType: 'conversation',
        scopeType,
        scopeId,
        autoStore: true,
        focusAreas: ['facts', 'decisions', 'events', 'preferences', 'relationships'],
        agentId: 'locomo-bench',
      });

      const diaIds = chunk.map(d => d.dia_id);
      const storedEntries = res.stored?.entries ?? [];
      const storedEntities = res.stored?.entities ?? [];

      // Debug: log extraction details
      if (debugMode) {
        const totalExtracted = res.meta?.totalExtracted ?? 0;
        const aboveThreshold = res.meta?.aboveThreshold ?? 0;
        const duplicates = res.meta?.duplicatesFound ?? 0;
        console.log(`    Chunk: extracted=${totalExtracted} aboveThreshold=${aboveThreshold} duplicates=${duplicates} stored=${storedEntries.length + storedEntities.length}`);
      }

      for (const stored of [...storedEntries, ...storedEntities]) {
        entryIdToDiaIds.set(stored.id, diaIds);
        extractedCount++;
      }
    } catch (error) {
      if (debugMode) {
        console.error(`  Extraction error for chunk: ${error instanceof Error ? error.message : String(error)}`);
      }
    }
  }

  // Wait for async embedding hooks to finish so evaluation isn't racing ingestion.
  const waitStart = Date.now();
  const timeoutMs = 10 * 60 * 1000; // 10 minutes
  while (Date.now() - waitStart < timeoutMs) {
    const stats = getEmbeddingQueueStats();
    if (stats.pending === 0 && stats.inFlight === 0) break;
    if (debugMode) {
      process.stdout.write(
        `  Waiting for embeddings... pending=${stats.pending} inFlight=${stats.inFlight}\r`
      );
    }
    await new Promise((r) => setTimeout(r, 250));
  }
  if (debugMode) process.stdout.write('\n');

  console.log(`  Ingested ${extractedCount} extracted memories (from ${dialogues.length} dialogues)`);
  return entryIdToDiaIds;
}

// =============================================================================
// RAW INGESTION (bypass LLM extraction for baseline testing)
// =============================================================================

async function ingestRawDialogues(
  ctx: AppContext,
  dialogues: LoCoMoDialogue[],
  scopeType: 'project' | 'session',
  scopeId: string,
  db: ReturnType<typeof drizzle>
): Promise<Map<string, string[]>> {
  const entryIdToDiaIds = new Map<string, string[]>();

  for (const dialogue of dialogues) {
    const entryId = generateId();
    const versionId = generateId();

    // Insert knowledge entry
    db.insert(schema.knowledge).values({
      id: entryId,
      scopeType,
      scopeId,
      title: `${dialogue.speaker}: ${dialogue.dia_id}`,
      category: 'fact',
      currentVersionId: versionId,
      isActive: true,
      createdBy: 'locomo-bench-raw',
    }).run();

    // Insert version with dialogue content
    db.insert(schema.knowledgeVersions).values({
      id: versionId,
      knowledgeId: entryId,
      versionNum: 1,
      content: dialogue.text,
      source: 'locomo-dialogue',
      confidence: 1.0,
      createdBy: 'locomo-bench-raw',
    }).run();

    // 1:1 mapping - each entry maps to exactly one dialogue ID
    entryIdToDiaIds.set(entryId, [dialogue.dia_id]);

    // Manually queue embedding (bypassing repository hooks)
    generateEmbeddingAsync({
      entryType: 'knowledge',
      entryId,
      versionId,
      content: dialogue.text,
      title: `${dialogue.speaker}: ${dialogue.dia_id}`,
    });
  }

  // Wait for embedding queue to drain
  // Wait for async embedding hooks to finish
  const waitStart = Date.now();
  const timeoutMs = 10 * 60 * 1000; // 10 minutes
  while (Date.now() - waitStart < timeoutMs) {
    const stats = getEmbeddingQueueStats();
    if (stats.pending === 0 && stats.inFlight === 0) break;
    if (debugMode) {
      process.stdout.write(
        `  Waiting for embeddings... pending=${stats.pending} inFlight=${stats.inFlight}\r`
      );
    }
    await new Promise((r) => setTimeout(r, 250));
  }
  if (debugMode) process.stdout.write('\n');

  console.log(`  Ingested ${dialogues.length} raw dialogues (1:1 mapping)`);
  return entryIdToDiaIds;
}

// =============================================================================
// QUERY FUNCTION
// =============================================================================

function createProductionQueryFunction(
  ctx: AppContext,
  sessionId: string,
  sqlite: InstanceType<typeof Database>,
  db: ReturnType<typeof drizzle>
) {
  const logger = pino({ level: debugMode ? 'debug' : 'warn' });
  const queryCache = new LRUCache<unknown>(100, 10 * 1024 * 1024);

  // Create pipeline dependencies with our LOCAL database
  // instead of using the global getDb() from connection.ts
  const pipelineDeps = createDependencies({
    getDb: () => db as unknown as ReturnType<typeof drizzle>,
    getSqlite: () => sqlite,
    getPreparedStatement: (sql: string) => sqlite.prepare(sql),
    cache: queryCache as typeof queryCache,
    perfLog: debugMode,
    logger,
    // Include production services from context
    queryRewriteService: ctx.services.queryRewrite ? {
      rewrite: (input) => ctx.services.queryRewrite!.rewrite(input),
      isAvailable: () => ctx.services.queryRewrite!.isAvailable(),
    } : undefined,
    embeddingService: ctx.services.embedding ? {
      embed: (text) => ctx.services.embedding!.embed(text),
      embedBatch: (texts) => ctx.services.embedding!.embedBatch(texts),
      isAvailable: () => ctx.services.embedding!.isAvailable(),
    } : undefined,
    vectorService: ctx.services.vector ? {
      searchSimilar: (embedding, entryTypes, limit) =>
        ctx.services.vector!.searchSimilar(embedding, entryTypes, limit),
      isAvailable: () => ctx.services.vector!.isAvailable(),
    } : undefined,
  });

  let queryCount = 0;

  return async (question: string) => {
    // Use production pipeline with all services including HyDE
    const result = await executeQueryPipelineAsync(
      {
        search: question,
        scope: { type: 'session' as const, id: sessionId, inherit: true },
        types: ['knowledge'],
        limit: 40,
        useFts5: true,
        semanticSearch: true,
        // Enable HyDE for better semantic matching
        enableHyDE: hydeEnabled,
        enableExpansion: expansionEnabled,
      },
      pipelineDeps
    );

    // Debug: show first query's results
    if (debugMode && queryCount < 1) {
      queryCount++;
      console.log(`\n  [DEBUG] Query: "${question.substring(0, 50)}..."`);
      console.log(`  [DEBUG] Pipeline returned: ${result.results.length} results`);
      if (result.results.length > 0) {
        const first = result.results[0];
        console.log(`  [DEBUG] Top result: id=${first?.id}, score=${first?.score?.toFixed(3)}`);
      }
    }

    return result.results.map(r => ({
      id: r.id,
      type: r.type,
      score: r.score,
      knowledge: r.type === 'knowledge' ? { source: (r.knowledge as { source?: string })?.source } : undefined,
    }));
  };
}

// =============================================================================
// MAIN BENCHMARK
// =============================================================================

async function runProductionBenchmark() {
  console.log('\n========================================');
  console.log('LoCoMo Benchmark (PRODUCTION PIPELINE)');
  console.log('========================================');
  console.log(`Sessions: ${maxSessions}`);
  if (maxDialogues < Infinity) {
    console.log(`Dialogues limit: ${maxDialogues} per session`);
  }
  console.log(`Query rewrite: hyde=${hydeEnabled} expansion=${expansionEnabled}`);
  console.log(`Ingestion: chunkSize=${chunkSize}, overlap=${chunkOverlap}`);
  console.log(`Retrieval: limit=40`);
  console.log('========================================\n');

  // Load dataset
  console.log('Loading LoCoMo dataset...');
  const sessions = await loadLoCoMoDataset();
  const stats = getDatasetStats(sessions);
  console.log(`Loaded: ${stats.totalSessions} sessions, ${stats.totalDialogues} dialogues, ${stats.totalQAPairs} QA pairs\n`);

  // Limit sessions if requested
  let sessionsToRun = sessions.slice(0, maxSessions);

  // Limit dialogues per session if requested
  if (maxDialogues < Infinity) {
    sessionsToRun = sessionsToRun.map(session => {
      const limitedDialogues = session.dialogues.slice(0, maxDialogues);
      const dialogueIds = new Set(limitedDialogues.map(d => d.dia_id));

      // Filter QA pairs to only those with ALL evidence in the ingested dialogues
      const filteredQaPairs = session.qaPairs.filter(qa =>
        qa.evidence.length > 0 && qa.evidence.every(eId => dialogueIds.has(eId))
      );

      return {
        ...session,
        dialogues: limitedDialogues,
        qaPairs: filteredQaPairs,
      };
    });

    const totalFilteredQa = sessionsToRun.reduce((sum, s) => sum + s.qaPairs.length, 0);
    console.log(`Limiting to ${maxDialogues} dialogues per session`);
    console.log(`Filtered to ${totalFilteredQa} QA pairs with evidence in ingested dialogues\n`);
  }

  // Run each session
  const allResults: Awaited<ReturnType<typeof evaluateSession>> = [];

  for (const session of sessionsToRun) {
    console.log(`\nSession ${session.sessionId}: ${session.dialogues.length} dialogues, ${session.qaPairs.length} QA pairs`);

    // Setup fresh production context for each session
    const { ctx, projectId, sqlite, db, cleanup } = await setupProductionContext();

    try {
      // Use a session scope (production-like capture) for all ingested memories.
      await ctx.repos.sessions.create({
        id: session.sessionId,
        projectId,
        name: `LoCoMo Session ${session.sessionId}`,
        purpose: 'LoCoMo production benchmark ingestion',
        agentId: 'locomo-bench',
        metadata: { source: 'locomo-benchmark' },
      });

      // Ingest dialogues - either via LLM extraction or raw ingestion
      const entryIdToDiaIds = rawIngestionMode
        ? await ingestRawDialogues(ctx, session.dialogues, 'session', session.sessionId, db)
        : await ingestWithProductionExtraction(ctx, session.dialogues, 'session', session.sessionId);

      // Create production query function (with local db for pipeline)
      const queryFn = createProductionQueryFunction(ctx, session.sessionId, sqlite, db);

      // Create ingest function that returns the pre-computed mapping
      const ingestFn = async (): Promise<Map<string, string>> => {
        // Convert Map<string, string[]> to Map<string, string> for compatibility
        const flatMap = new Map<string, string>();
        for (const [entryId, diaIds] of entryIdToDiaIds) {
          flatMap.set(entryId, diaIds.join(','));
        }
        return flatMap;
      };

      // Evaluate session with progress
      let lastProgress = 0;
      const results = await evaluateSession(session, ingestFn, queryFn, (done, total) => {
        const pct = Math.floor((done / total) * 100);
        if (pct >= lastProgress + 10) {
          process.stdout.write(`  Progress: ${pct}%\r`);
          lastProgress = pct;
        }
      });

      // Debug: show first few results
      if (debugMode) {
        const sample = results.slice(0, 3);
        for (const r of sample) {
          console.log(`\n  Q: "${r.question.substring(0, 60)}..."`);
          console.log(`  Ground truth: ${r.groundTruthEvidence.join(', ')}`);
          console.log(`  Retrieved: ${r.retrievedEvidence.length} entries`);
          if (r.retrievedEvidence.length > 0) {
            console.log(`    First: ${r.retrievedEvidence[0]}`);
          }
        }
      }

      allResults.push(...results);

      // Quick session summary
      const sessionMRR = results.reduce((sum, r) => sum + r.mrr, 0) / results.length;
      console.log(`  MRR: ${(sessionMRR * 100).toFixed(1)}%`);
    } finally {
      await cleanup();
    }
  }

  // Compile and print results
  const benchmarkResults = compileBenchmarkResults(allResults, {
    useEmbeddings: true,
    sessionsRun: sessionsToRun.length,
  });

  printBenchmarkResults(benchmarkResults);
}

// =============================================================================
// MAIN
// =============================================================================

runProductionBenchmark()
  .then(() => process.exit(0))
  .catch((err) => {
    console.error(err);
    process.exit(1);
  });
